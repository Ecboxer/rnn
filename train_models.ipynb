{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text from shksp_complete_works.txt\n",
      "Parsed 98720 sentences\n",
      "Found 32433 unique word tokens\n",
      "Using vocabulary size 21622\n",
      "The least frequent word in our vocabulary is \"sequestration-\" appearing 1 times\n",
      "Example sentence: \"SENTENCE_START what's your name? SENTENCE_END\"\n",
      "Example sentence after pre-processing: \"[u'SENTENCE_START', u'what', u\"'s\", u'your', u'name', u'?', u'SENTENCE_END']\"\n",
      "X:\n",
      "SENTENCE_START what wilt thou do ?\n",
      "[0, 38, 348, 33, 45, 15]\n",
      "y:\n",
      "what wilt thou do ? SENTENCE_END\n",
      "[38, 348, 33, 45, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus, tokenized_sentences, sentences, word_freq, vocab, idx2word, word2idx, X_train, y_train = preprocessing_pipeline('shksp_complete_works.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NEPOCH = 20\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = GRUTheano(len(idx2word), HIDDEN_DIM)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[0], y_train[0], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print 'SGD step time: ~%f millisenconds' % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train, y_train, LEARNING_RATE, NEPOCH, decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_parameters_theano_gru(model, 'data/shksp_trained_model.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dickens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text from shksp_complete_works.txt\n",
      "Parsed 98720 sentences\n",
      "Found 32433 unique word tokens\n",
      "Using vocabulary size 21622\n",
      "The least frequent word in our vocabulary is \"sequestration-\" appearing 1 times\n",
      "Example sentence: \"SENTENCE_START what's your name? SENTENCE_END\"\n",
      "Example sentence after pre-processing: \"[u'SENTENCE_START', u'what', u\"'s\", u'your', u'name', u'?', u'SENTENCE_END']\"\n",
      "X:\n",
      "SENTENCE_START what wilt thou do ?\n",
      "[0, 38, 348, 33, 45, 15]\n",
      "y:\n",
      "what wilt thou do ? SENTENCE_END\n",
      "[38, 348, 33, 45, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus, tokenized_sentences, sentences, word_freq, vocab, idx2word, word2idx, X_train, y_train = preprocessing_pipeline(['dickens_bleak_house.txt', 'dickens_christmas_carol.txt', 'dickens_copperfield.txt', 'dickens_great_exp.txt', 'dickens_hard_times.txt', 'dickens_little_dorrit.txt', 'dickens_nickleby.txt', 'dickens_oliver.txt', 'dickens_pickwick.txt', 'dickens_two_cities.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NEPOCH = 20\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = GRUTheano(len(idx2word), HIDDEN_DIM)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[0], y_train[0], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print 'SGD step time: ~%f millisenconds' % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train, y_train, LEARNING_RATE, NEPOCH, decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_parameters_theano_gru(model, 'data/dickens_trained_model.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text from shksp_complete_works.txt\n",
      "Parsed 98720 sentences\n",
      "Found 32433 unique word tokens\n",
      "Using vocabulary size 21622\n",
      "The least frequent word in our vocabulary is \"sequestration-\" appearing 1 times\n",
      "Example sentence: \"SENTENCE_START what's your name? SENTENCE_END\"\n",
      "Example sentence after pre-processing: \"[u'SENTENCE_START', u'what', u\"'s\", u'your', u'name', u'?', u'SENTENCE_END']\"\n",
      "X:\n",
      "SENTENCE_START what wilt thou do ?\n",
      "[0, 38, 348, 33, 45, 15]\n",
      "y:\n",
      "what wilt thou do ? SENTENCE_END\n",
      "[38, 348, 33, 45, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus, tokenized_sentences, sentences, word_freq, vocab, idx2word, word2idx, X_train, y_train = preprocessing_pipeline(['plato_apology_crito_phaedo.txt', 'plato_euthyphro.txt', 'plato_gorgias.txt', 'plato_laws.txt', 'plato_meno.txt', 'plato_phaedrus.txt', 'plato_protagoras.txt', 'plato_republic.txt', 'plato_symposium.txt', 'plato_theaetetus.txt', 'plato_timaeus.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NEPOCH = 20\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = GRUTheano(len(idx2word), HIDDEN_DIM)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[0], y_train[0], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print 'SGD step time: ~%f millisenconds' % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train, y_train, LEARNING_RATE, NEPOCH, decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_parameters_theano_gru(model, 'data/plato_trained_model.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shakespeare, Dickens and Plato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text from shksp_complete_works.txt\n",
      "Parsed 98720 sentences\n",
      "Found 32433 unique word tokens\n",
      "Using vocabulary size 21622\n",
      "The least frequent word in our vocabulary is \"sequestration-\" appearing 1 times\n",
      "Example sentence: \"SENTENCE_START what's your name? SENTENCE_END\"\n",
      "Example sentence after pre-processing: \"[u'SENTENCE_START', u'what', u\"'s\", u'your', u'name', u'?', u'SENTENCE_END']\"\n",
      "X:\n",
      "SENTENCE_START what wilt thou do ?\n",
      "[0, 38, 348, 33, 45, 15]\n",
      "y:\n",
      "what wilt thou do ? SENTENCE_END\n",
      "[38, 348, 33, 45, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus, tokenized_sentences, sentences, word_freq, vocab, idx2word, word2idx, X_train, y_train = preprocessing_pipeline(['dickens_bleak_house.txt', 'dickens_christmas_carol.txt', 'dickens_copperfield.txt', 'dickens_great_exp.txt', 'dickens_hard_times.txt', 'dickens_little_dorrit.txt', 'dickens_nickleby.txt', 'dickens_oliver.txt', 'dickens_pickwick.txt', 'dickens_two_cities.txt', 'plato_apology_crito_phaedo.txt', 'plato_euthyphro.txt', 'plato_gorgias.txt', 'plato_laws.txt', 'plato_meno.txt', 'plato_phaedrus.txt', 'plato_protagoras.txt', 'plato_republic.txt', 'plato_symposium.txt', 'plato_theaetetus.txt', 'plato_timaeus.txt', 'shksp_complete_works.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NEPOCH = 20\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = GRUTheano(len(idx2word), HIDDEN_DIM)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[0], y_train[0], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print 'SGD step time: ~%f millisenconds' % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train, y_train, LEARNING_RATE, NEPOCH, decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_parameters_theano_gru(model, 'data/dickens_plato_shksp_trained_model.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the works of three authors separately and together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
